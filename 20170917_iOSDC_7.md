# CoreMLでアイドル顔識別アプリを作ろう
* iOSエンジニアが機械学習にチャレンジしてみた
* iOS11公開前なので見せれる範囲での発表

## Vision
* 画像認識処理用フレームワーク
* メジャーな画像認識処理を標準で提供

* Face Detection
* Face Landmarks
* Rectangle Detection
* Text Detection

Vision で用意されているものがなければ、Core MLを使う

## Core ML
* 機械学習フレームワーク（推論のみ）
* デバイス単体で動作
* 実行時にサーバー不要・高速・セキュア
* CPU/GPUに最適化されておりパワフル

* Core MLモデル
  * ネットワーク構造、学習済みの重み
  * ドキュメント/メタデータ
  * SwiftとのIFとなるクラス定義

* Core MLモデルの準備
  1. 訓練済みのCoreMLモデルを使う
    * その他、githubなどで公開されているモデルを使う
    * 使えるものがなければ2.

  2. Core ML Toolsによる変換
    * 訓練済みの機械学習済みのモデル（Python）も多数公開されている
    * 使えるものがなければ3.

  3. 機械学習のコードをPhythonで実装＆訓練して、変換

## 今回の手順
1. 教師データの準備
  * クローラで画像を収集
    * 画像検索API
    * スクレイピング
  * 画像の前処理、ラベル付け

2. モデルの実装
  * 画像の多クラス分類問題
  * 畳み込みニューラルネットワーク
    * 元画像にフィルタをマッピングして特徴を抽出

  * 機械学習ライブラリ
    * Core ML Toolsがサポートしているものを選択する
    * kerasを採用

3. 訓練
  * クラウド上での学習
    * GPUは必須（MBP+CPUで数日かかる処理 -> GPUだと数時間）
    * 教師データ画像はs3に配置
    * AWS Deep Laearning AMIs

4. 学習済みモデルの変換
5. アプリへの組み込み
  * 顔識別
    1. 学習済みCoreMLモデルのロード
    2. Vision+CoreMLで推論を実行
    3. 識別結果の取得

    ```
    let idleClassifier = IdleClassifier()
    let model = VNCoreMLModel(for: idleClassifier.model)

    let image: CIImage = …
    let handler = VNlmageRequestHandler(cilmage: image)
    try handler.perform([
      VNCoreMLRequest(model: model) {(req, err) in

        let res = req.results!.first as! VNClassificationObservation
        let name = res.identifier
        let probability = Int(res.confidence * 100)
        print ("識別結果 \(name):\(probability)%")
    ```

  * 成長により顔が変化する
    * 継続的な識別精度の向上が必要
      * 誤検知の報告機能を利用
      * クローラーによる継続的な収集&ラベル付け
    * CoreMLモデルの動的置換が可能になっている
